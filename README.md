# Explainabillity of ML algorithms in Hate Speech Detection
 This repository contains the code associated with the research seminar in “Ethical Aspects of Machine Learning Methods”. In this context, this work presents an NLP  approach based on pre-trained and adapated FastText embeddings to determine the potential trade-off between the accuracy and explainability [measured by LIME] of hate speech detection algorithms such as SVMs, XGBoost and LSTMs.
